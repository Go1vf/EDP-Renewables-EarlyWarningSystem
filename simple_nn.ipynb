{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Pre-processed Data\n",
    "def read(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df.sort_values(by=['Turbine_ID','Timestamp'], inplace=True)\n",
    "    return df\n",
    "\n",
    "data = {}\n",
    "for system, path in {\n",
    "    \"GEARBOX\": \"./data/GEARBOX_processed.csv\",\n",
    "    \"BEARING\": \"./data/GENERATOR_BEARING_processed.csv\",\n",
    "    \"GENERATOR\": \"./data/GENERATOR_processed.csv\",\n",
    "    \"HYDRAULIC\": \"./data/HYDRAULIC_GROUP_processed.csv\",\n",
    "    \"TRANSFORMER\": \"./data/TRANSFORMER_processed.csv\",\n",
    "    \"ALL\": \"./data/all_signals_processed.csv\"\n",
    "    }.items():\n",
    "    data[system] = read(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain X for past n steps, Y and corresponding lead time\n",
    "def get_XY_with_steps(data, x_steps=1):\n",
    "    X, Y, lead, event = [], [], [], []\n",
    "    for i in range(x_steps, len(data)-1):\n",
    "        x = data.iloc[i-x_steps:i+1, 2:-4].to_numpy()\n",
    "        X.append(x.flatten())\n",
    "        Y.append(data.iloc[i+1, -1])\n",
    "        lead.append(data.iloc[i+1, -2])\n",
    "        event.append(data.iloc[i+1, 0] + \" \" + data.iloc[i+1, -3])\n",
    "    return {\n",
    "        \"X\": X,\n",
    "        \"Y\": Y,\n",
    "        \"Lead Time\": lead,\n",
    "        \"Event\": event\n",
    "        }\n",
    "\n",
    "# Function to undersample the majority class so that the data is balanced\n",
    "def undersample_majority(x, y):\n",
    "    class_counts = np.bincount(y)\n",
    "    minority_class = np.argmin(class_counts)\n",
    "    majority_class = np.argmax(class_counts)\n",
    "    majority_to_keep = class_counts[minority_class]\n",
    "    majority_idx = np.where(y == majority_class)[0]\n",
    "    majority_idx_new = np.random.choice(majority_idx, majority_to_keep, replace=False)\n",
    "    minority_idx = np.where(y == minority_class)[0]\n",
    "    idx_to_keep = np.concatenate((majority_idx_new, minority_idx))\n",
    "    return x[idx_to_keep], y[idx_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Gearbox data for example\n",
    "df = data[\"GEARBOX\"]\n",
    "\n",
    "# Parameters\n",
    "test_size = 0.25\n",
    "val_size = 0.15\n",
    "steps = 6*24\n",
    "\n",
    "# Seperate and save test data for later use\n",
    "test_data = df.sort_values(by='Timestamp')[:int(len(df) * test_size)].reset_index(drop=True)\n",
    "train_data = df.sort_values(by='Timestamp')[int(len(df) * test_size):].reset_index(drop=True)\n",
    "\n",
    "# Split training data into X, Y and lead time\n",
    "train_xy = train_data.groupby(\"Turbine_ID\").apply(lambda group: get_XY_with_steps(group, steps)).reset_index()\n",
    "X_train, Y_train = [], []\n",
    "for _, row in train_xy.iterrows():\n",
    "    X_train = X_train + row[0]['X']\n",
    "    Y_train = Y_train + row[0]['Y']\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "\n",
    "# Balance the training data\n",
    "X_train_balanced, Y_train_balanced = undersample_majority(X_train, Y_train)\n",
    "\n",
    "# Seperate and save validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_balanced, Y_train_balanced, test_size=val_size, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26110, 6090), (26110,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "816/816 [==============================] - 36s 43ms/step - loss: 67.3990 - accuracy: 0.5267 - val_loss: 1.6524 - val_accuracy: 0.5247\n",
      "Epoch 2/100\n",
      "816/816 [==============================] - 33s 41ms/step - loss: 1.4372 - accuracy: 0.5871 - val_loss: 1.5787 - val_accuracy: 0.5252\n",
      "Epoch 3/100\n",
      "816/816 [==============================] - 30s 37ms/step - loss: 10.7031 - accuracy: 0.5949 - val_loss: 2.7262 - val_accuracy: 0.5206\n",
      "Epoch 4/100\n",
      "816/816 [==============================] - 31s 38ms/step - loss: 1.2432 - accuracy: 0.6606 - val_loss: 1.1120 - val_accuracy: 0.6890\n",
      "Epoch 5/100\n",
      "816/816 [==============================] - 31s 38ms/step - loss: 2.7407 - accuracy: 0.6516 - val_loss: 0.7310 - val_accuracy: 0.7220\n",
      "Epoch 6/100\n",
      "816/816 [==============================] - 32s 39ms/step - loss: 2.8971 - accuracy: 0.6682 - val_loss: 88.4491 - val_accuracy: 0.5098\n",
      "Epoch 7/100\n",
      "816/816 [==============================] - 32s 39ms/step - loss: 4.5124 - accuracy: 0.5691 - val_loss: 1.0314 - val_accuracy: 0.6181\n",
      "Epoch 8/100\n",
      "816/816 [==============================] - 32s 39ms/step - loss: 3.2208 - accuracy: 0.6423 - val_loss: 0.7115 - val_accuracy: 0.4957\n",
      "Epoch 9/100\n",
      "816/816 [==============================] - 32s 40ms/step - loss: 1.2743 - accuracy: 0.6264 - val_loss: 1.0665 - val_accuracy: 0.6198\n",
      "Epoch 10/100\n",
      "816/816 [==============================] - 32s 39ms/step - loss: 1.1371 - accuracy: 0.6902 - val_loss: 0.6115 - val_accuracy: 0.7402\n",
      "Epoch 11/100\n",
      "816/816 [==============================] - 32s 40ms/step - loss: 1.0953 - accuracy: 0.6931 - val_loss: 1.4466 - val_accuracy: 0.5211\n",
      "Epoch 12/100\n",
      "816/816 [==============================] - 32s 39ms/step - loss: 1.1398 - accuracy: 0.6799 - val_loss: 0.9729 - val_accuracy: 0.5493\n",
      "Epoch 13/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 1.2044 - accuracy: 0.6582 - val_loss: 0.7558 - val_accuracy: 0.7190\n",
      "Epoch 14/100\n",
      "816/816 [==============================] - 29s 35ms/step - loss: 1.0902 - accuracy: 0.6724 - val_loss: 0.6921 - val_accuracy: 0.7261\n",
      "Epoch 15/100\n",
      "816/816 [==============================] - 29s 35ms/step - loss: 2.0444 - accuracy: 0.6711 - val_loss: 1.1742 - val_accuracy: 0.3793\n",
      "Epoch 16/100\n",
      "816/816 [==============================] - 30s 36ms/step - loss: 9.5236 - accuracy: 0.6481 - val_loss: 0.6885 - val_accuracy: 0.7376\n",
      "Epoch 17/100\n",
      "816/816 [==============================] - 30s 37ms/step - loss: 1.0832 - accuracy: 0.7116 - val_loss: 0.6775 - val_accuracy: 0.7433\n",
      "Epoch 18/100\n",
      "816/816 [==============================] - 29s 35ms/step - loss: 1.0167 - accuracy: 0.7199 - val_loss: 0.6263 - val_accuracy: 0.7422\n",
      "Epoch 19/100\n",
      "816/816 [==============================] - 29s 35ms/step - loss: 1.5267 - accuracy: 0.6974 - val_loss: 0.7139 - val_accuracy: 0.7214\n",
      "Epoch 20/100\n",
      "815/816 [============================>.] - ETA: 0s - loss: 1.0113 - accuracy: 0.7083Restoring model weights from the end of the best epoch: 10.\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 1.0116 - accuracy: 0.7084 - val_loss: 1.0261 - val_accuracy: 0.7279\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "def make_model(input_size):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation=\"relu\", input_shape=(input_size,)),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = make_model(X_train.shape[1])\n",
    "\n",
    "# Build early stopping feature to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Class weight that punish false positive rate\n",
    "class_weights = {0: 1, 1: 5}\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train, y_train.astype(float), \n",
    "    class_weight=class_weights,\n",
    "    validation_data=(X_val, y_val.astype(float)), \n",
    "    epochs=100, \n",
    "    batch_size=32, \n",
    "    callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 1s 4ms/step\n",
      "Accuracy: 0.740234375\n",
      "Precision: 0.6604042129234273\n",
      "Recall: 0.9982788296041308\n",
      "F1 Score: 0.7949289018331335\n"
     ]
    }
   ],
   "source": [
    "# Obtain evaluation metrics for the model\n",
    "def evaluate_model(y_pred, y_true):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    print(f\"Precision: {precision}\")\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    print(f\"Recall: {recall}\")\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "y_true = y_val.astype(int)\n",
    "\n",
    "evaluate_model(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107803, 6090), (107803,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split testing data into X, Y and lead time\n",
    "test_xy = test_data.groupby(\"Turbine_ID\").apply(lambda group: get_XY_with_steps(group, steps)).reset_index()\n",
    "X_test, Y_test, Y_lead, Y_event = [], [], [], []\n",
    "for _, row in test_xy.iterrows():\n",
    "    X_test = X_test + row[0]['X']\n",
    "    Y_test = Y_test + row[0]['Y']\n",
    "    Y_lead = Y_lead + row[0]['Lead Time']\n",
    "    Y_event = Y_event + row[0]['Event']\n",
    "X_test, Y_test, Y_lead, Y_event = np.array(X_test), np.array(Y_test), np.array(Y_lead), np.array(Y_event)\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3369/3369 [==============================] - 120s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = Y_test.astype(int)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 0, [59])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP, FN, TP_lead = 0, 0, []\n",
    "warnings = {}\n",
    "for i in range(len(Y_test)):\n",
    "    if y_true[i] == 0 and y_pred[i] == 1:\n",
    "        FP += 1\n",
    "    elif y_true[i] == 1:\n",
    "        event = Y_event[i]\n",
    "        lead_time = Y_lead[i]\n",
    "        if event not in warnings and y_pred[i] == 0:\n",
    "            warnings[event] = -1\n",
    "        elif event not in warnings and y_pred[i] == 1:\n",
    "            warnings[event] = lead_time\n",
    "        elif event in warnings and warnings[event] < 0:\n",
    "            if y_pred[i] == 1:\n",
    "                warnings[event] = lead_time\n",
    "for event, lead in warnings.items():\n",
    "    if lead < 0:\n",
    "        FN += 1\n",
    "    else:\n",
    "        TP_lead.append(lead)\n",
    "\n",
    "FP, FN, TP_lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5286333.333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R, M, I = 100000, 20000, 5000\n",
    "savings = 0\n",
    "for l in TP_lead:\n",
    "    savings += (l / 60) * (R - M)\n",
    "savings -= FP * I\n",
    "savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/model_0404\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/model_0404\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "# model.save('./saved_models/model_0404')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model later\n",
    "# model = load_model('./saved_models/model_0404')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
